{
  "hash": "baa5ae50e60cd2adc833eeb796a6ef35",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"CH.00 Describing Data\"\nauthor:\n  - name: Gordon Wright\n    role: remixer\n    orcid: 0000-0003-1689-0557\n    email: g.wright@gold.ac.uk\n    affiliations:\n      - name: LittleMonkeyLab @ Goldsmiths Psychology\n        address: Goldsmiths, University of London\n        city: London\n        state: UK\n        postal-code: SE14 6NW\n  - name: Matthew Crump\n    role: Original Author\n---\n\n\n\n\n::: callout\nThis placeholder/indicative text is copied (and minimally edited) from\nProfessor Matthew Crump (et al)'s \"Answering Questions with Data\"\n\nOnline Textbook: https://crumplab.github.io/statistics/\n\nCitation: Crump, M. J. C., Navarro, D. J., & Suzuki, J. (2019, June 5).\nAnswering Questions with Data (Textbook): Introductory Statistics for\nPsychology Students. https://doi.org/10.17605/OSF.IO/JZE52\n\nAll resources are released under a creative commons licence CC BY-SA\n4.0. Click the link to read more about the license, or read more below\nin the license section.\n:::\n\n\n\n\n\n\n\n\n\n# Describing Data {#DescribingData}\n\n> Far better an approximate answer to the right question, which is often\n> vague, than an exact answer to the wrong question, which can always be\n> made precise. ---John W. Tukey\n\nThis chapter is about **descriptive statistics**. These are tools for\ndescribing data. Some things to keep in mind as we go along are:\n\n1.  There are lots of different ways to describe data\n2.  There is more than one \"correct\" way, and you get to choose the most\n    \"useful\" way for the data that you are describing\n3.  It is possible to invent new ways of describing data, all of the\n    ways we discuss were previously invented by other people, and they\n    are commonly used because they are useful.\n4.  Describing data is necessary because there is usually too much of\n    it, so it doesn't make any sense by itself.\n\n## This is what too many numbers looks like\n\nLet's say you wanted to know how happy people are. So, you ask thousands\nof people on the street how happy they are. You let them pick any number\nthey want from negative infinity to positive infinity. Then you record\nall the numbers. Now what?\n\nWell, how about you look at the numbers and see if that helps you\ndetermine anything about how happy people are. What could the numbers\nlook like. Perhaps something like this:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|     |      |     |     |     |     |      |     |      |     |\n|----:|-----:|----:|----:|----:|----:|-----:|----:|-----:|----:|\n|  328|  -187|  378|  684| -191| -273|   540| -128|  -552|  214|\n|  -98|   111|  163|   57|  603|  126|  -320|  251|  -300| -772|\n| -291|  -359| -319| -244|  325| -377|   617|  310|  -589| -435|\n|  289|   446| -230|  117|  264|  846|   162|  276|   250|  556|\n|  197|   359|   34| 1069| 1067|  542|   311|  143|   354| -654|\n| -118|  -246|  260|  132|   96|  523|   203| -134|  -665| -765|\n| -496|    -4| -254|  478| -319|  287|  -172|  274|   615|  -69|\n|  336|  -486|  306| -187| -753| -543|  -693| -346|   347|  -24|\n|  715|  -325|  195|   69|  509|  324|   502|  701|   653|  -54|\n|  840|   589|    5| -635|   39| -210|  -684|  292|   300|  104|\n| -301|   805|  374|  772|  675|  -46|   420| -442|    63| -182|\n|  632|   794|  747|  308| -258|  758|  -388|  202|  -326|  321|\n|  -53|  -213|  742|  144|  289|  390|   347|  340|   235| -487|\n| -694|   800| -246|  475| 1037|  558|    62|  133|   -72|  690|\n|  426|   986|  700|  217|  985|  501|   114| -328|   135| -610|\n|  592|  -874| -138|  128| -115|  363| -1435| 1100|  -345| -328|\n|  130|    51|   98| -457| -162|  -61|  -454| -312|   113| -552|\n| -760|   130|  402|  934| -119|  820|     1|  -37|   409|  -15|\n|  289|   747|  717| -662| -153|  419|  -197| 1854|   116| -651|\n| -356|   287| -205|  183| -873| -340|  -147| -177|    74|  550|\n|  145|  1013| -377|   63|   48| -413|   311| -828|  -790|  347|\n|  239|   267|  190| -559| -321|  945|  -369| 1165| -1083|  205|\n| -354|   -72| -216| -985|  241|  802|    88|  222|   446|  401|\n|  516|   192|  291| -151|  223|   82|   741|  998|   225|  622|\n| -178|  -215|  193| -181|  268| -735|   727|  107|  1454| -441|\n| -302|  -912| -133| -175|   95| -224|  -296| -352|   144|  -20|\n|  -86|  -241|  572|  736| -394|  241|   436|  411| -1453|  603|\n| -349|   153|  282|  104|   62|  806|  -154|  142|  -338|  561|\n|  216|  -172|  918| -318|   53|  337|  -594|   78|   -36|  282|\n|  200|   757|  135|  878|  -40|  -35|  -193|  -13|   525|   15|\n| -657|   122| 1111|   97| -466|  173|   416| 1028|  -682| -572|\n|  206|   287|  540|  123|  391|  420|   155|  885|  -690| -640|\n|  404|  -309|  834|  405|  988|  471|   -64| -909|  -149|  177|\n|  364|    -8| -503|    0|   32|  -44|  -175|  570|   625|  681|\n|  926|   144|   93| -221|  309| 1001|   728|   21|   779| -926|\n| -249|  -391|  -80| 1014|  375| -222|    68| -281|   622| -498|\n| -173|   -37|  137|   26|  243|  306|  -207| -435|  -232| -229|\n| 1118|  -335|  556|  289| -432| -441|    70|  390|   -84|  594|\n| -329|   165|  489| -319| -682|  204|  -755|  474|   972|  226|\n|  185|   371|  773|   34| -487|  570|   229|  -41|   308|   49|\n|  758|   539| -410|  148|  414| -844|   630|  688|   696| -218|\n| -716|   293| -801|  666|  -69|  743|  -793|  199|    13|  273|\n|  250|   -48| -602|  330| -277| -181|    74| -608|   214|  942|\n|   84|   997| 1363| 1072| -535|   11|   759| -531|  -360| 1138|\n| -103|   593|  507|  380|  351|  564|   482| -159|   432|  346|\n|  779|   -63| 1604|  354| 1007|  462|  -254|  231|  -424| -190|\n| -701| -1080|  714| -483|  519|  113|    45|  239|    33| -689|\n| -822|   565| -779| 1186|  415|  849|   785|  198|   443|  603|\n|  391|   540| -577|  309|   30| -102|   915|  610| -1104|  404|\n| -284|   390| -485|   53|  522|  230|  -243|  458|   601|  155|\n\n\n:::\n:::\n\n\n\n\nNow, what are you going to with that big pile of numbers? Look at it all\nday long? When you deal with data, it will deal so many numbers to you\nthat you will be overwhelmed by them. That is why we need ways to\ndescribe the data in a more manageable fashion.\n\nThe complete description of the data is always the data itself.\n**Descriptive statistics** and other tools for describing data go one\nstep further to summarize aspects of the data. Summaries are a way to\ncompress the important bits of a thing down to a useful and manageable\ntidbit. It's like telling your friends why they should watch a movie:\nyou don't replay the entire movie for them, instead you hit the\nhighlights. Summarizing the data is just like a movie preview, only for\ndata.\n\n## Look at the data\n\nWe already tried one way of looking at the numbers, and it wasn't\nuseful. Let's look at some other ways of looking at the numbers, using\ngraphs.\n\n### Stop, plotting time (o o oh) U can plot this\n\nLet's turn all of the numbers into dots, then show them in a graph.\nNote, when we do this, we have not yet summarized anything about the\ndata. Instead, we just look at all of the data in a visual format,\nrather than looking at the numbers.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Pretend happiness ratings from 500 people](chapter_files/figure-html/fig-happyPlot-1.png){#fig-happyPlot width=75%}\n:::\n:::\n\n\n\n\n@fig-happyPlot shows 500 measurements of happiness. The graph has two\naxes. The horizontal **x-axis**, going from left to right is labeled\n\"Index\". The vertical **y-axis**, going up and down, is labelled\n\"happiness\". Each dot represents one measurement of every person's\nhappiness from our pretend study. Before we talk about what we can and\ncannot see about the data, it is worth mentioning that the way you plot\nthe data will make some things easier to see and some things harder to\nsee. So, what can we now see about the data?\n\nThere are lots of dots everywhere. It looks like there are 500 of them\nbecause the index goes to 500. It looks like some dots go as high as\n1000-1500 and as low as -1500. It looks like there are more dots in the\nmiddle-ish area of the plot, sort of spread about 0.\n\n> Take home: we can see all the numbers at once by putting them in a\n> plot, and that is much easier and more helpful than looking at the raw\n> numbers.\n\nOK, so if these dots represent how happy 500 people are, what can we say\nabout those people? First, the dots are kind of all over the place, so\ndifferent people have different levels of happiness. Are there any\ntrends? Are more people happy than unhappy, or vice-versa? It's hard to\nsee that in the graph, so let's make a different one, called a\n**histogram**\n\n### Histograms\n\nMaking a histogram will be our first act of officially summarizing\nsomething about the data. We will no longer look at the individual bits\nof data, instead we will see how the numbers group together. Let's look\nat @fig-happyHist, a histogram of the happiness data, and then explain\nit.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A histogram of the happiness ratings](chapter_files/figure-html/fig-happyHist-1.png){#fig-happyHist width=75%}\n:::\n:::\n\n\n\n\nThe dots have disappeared, and now we some bars. Each bar is a summary\nof the dots, representing the number of dots (frequency count) inside a\nparticular range of happiness, also called **bins**. For example, how\nmany people gave a happiness rating between 0 and 500? The fifth bar,\nthe one between 0 and 500 on the x-axis, tells you how many. Look how\ntall that bar is. How tall is it? The height is shown on the y-axis,\nwhich provides a frequency count (the number of dots or data points). It\nlooks like around 150 people said their happiness was between 0-500.\n\nMore generally, we see there are many bins on the x-axis. We have\ndivided the data into bins of 500. Bin #1 goes from -2000 to -1500, bin\n#2 goes from -1500 to -1000, and so on until the last bin. To make the\nhistogram, we just count up the number of data points falling inside\neach bin, then plot those frequency counts as a function of the bins.\nVoila, a histogram.\n\nWhat does the histogram help us see about the data? First, we can see\nthe **shape** of data. The shape of the histogram refers to how it goes\nup and down. The shape tells us where the data is. For example, when the\nbars are low we know there isn't much data there. When the bars are\nhigh, we know there is more data there. So, where is most of the data?\nIt looks like it's mostly in the middle two bins, between -500 and 500.\nWe can also see the **range** of the data. This tells us the minimums\nand the maximums of the data. Most of the data is between -1500 and\n+1500, so no infinite sadness or infinite happiness in our data-set.\n\nWhen you make a histogram you get to choose how wide each bar will be.\nFor example, below are four different histograms of the very same\nhappiness data. What changes is the width of the bins.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Four histograms of the same data using different bin widths](chapter_files/figure-html/fig-manyhistbin-1.png){#fig-manyhistbin width=75%}\n:::\n:::\n\n\n\n\nAll of the histograms have roughly the same overall shape: From left to\nright, the bars start off small, then go up, then get small again. In\nother words, as the numbers get closer to zero, they start to occur more\nfrequently. We see this general trend across all the histograms. But,\nsome aspects of the trend fall apart when the bars get really narrow.\nFor example, although the bars generally get taller when moving from\n-1000 to 0, there are some exceptions and the bars seem to fluctuate a\nlittle bit. When the bars are wider, there are less exceptions to the\ngeneral trend. How wide or narrow should your histogram be? It's a\nGoldilocks question. Make it just right for your data.\n\n## Important Ideas: Distribution, Central Tendency, and Variance\n\nLet's introduce three important terms we will use a lot,\n**distribution**, **central tendency**, and **variance**. These terms\nare similar to their everyday meanings (although I suspect most people\ndon't say central tendency very often).\n\n**Distribution.** When you order something from Amazon, where does it\ncome from, and how does it get to your place? That stuff comes from one\nof Amazon's distribution centers. They distribute all sorts of things by\nspreading them around to your doorstep. \"To Distribute\"\" is to spread\nsomething. Notice, the data in the histogram is distributed, or spread\nacross the bins. We can also talk about a distribution as a noun. The\nhistogram is a distribution of the frequency counts across the bins.\nDistributions are **very, very, very, very, very** important. They can\nhave many different shapes. They can describe data, like in the\nhistogram above. And as we will learn in later chapters, they can\n**produce** data. Many times we will be asking questions about where our\ndata came from, and this usually means asking what kind of distribution\ncould have created our data (more on that later.)\n\n**Central Tendency** is all about sameness: What is common about some\nnumbers? For example, is there anything similar about all of the numbers\nin the histogram? Yes, we can say that most of them are near 0. There is\na tendency for most of the numbers to be centered near 0. Notice we are\nbeing cautious about our generalization about the numbers. We are not\nsaying they are all 0. We are saying there is a tendency for many of\nthem to be near zero. There are lots of ways to talk about the central\ntendency of some numbers. There can even be more than one kind of\ntendency. For example, if lots of the numbers were around -1000, and a\nsimilar large amount of numbers were grouped around 1000, we could say\nthere was two tendencies.\n\n**Variance** is all about different*ness*: What is different about some\nnumbers?. For example, is there anything different about all of the\nnumbers in the histogram? YES!!! The numbers are not all the same! When\nthe numbers are not all the same, they must vary. So, the variance in\nthe numbers refers to how the numbers are different. There are many ways\nto summarize the amount of variance in the numbers, and we discuss these\nvery soon.\n\n## Measures of Central Tendency (Sameness)\n\nWe've seen that we can get a sense of data by plotting dots in a graph,\nand by making a histogram. These tools show us what the numbers look\nlike, approximately how big and small they are, and how similar and\ndifferent they are from another. It is good to get a feeling about the\nnumbers in this way. But, these visual sensitudes are not very precise.\nIn addition to summarizing numbers with graphs, we can summarize numbers\nusing numbers (NO, please not more numbers, we promise numbers can be\nyour friend).\n\n### From many numbers to one\n\nMeasures of central have one important summary goal: to reduce a pile of\nnumbers to a single number that we can look at. We already know that\nlooking at thousands of numbers is hopeless. Wouldn't it be nice if we\ncould just look at one number instead? We think so. It turns out there\nare lots of ways to do this. Then, if your friend ever asks the\nfrightening question, \"hey, what are all these numbers like?\". You can\nsay they are like this one number right here.\n\nBut, just like in Indiana Jones and the Last Crusade (highly recommended\nmovie), you must choose your measure of central tendency wisely.\n\n### Mode\n\nThe **mode** is the most frequently occurring number in your\nmeasurement. That is it. How do you find it? You have to count the\nnumber of times each number appears in your measure, then whichever one\noccurs the most, is the mode.\n\n> Example: 1 1 1 2 3 4 5 6\n\nThe mode of the above set is 1, which occurs three times. Every other\nnumber only occurs once.\n\nOK fine. What happens here:\n\n> Example: 1 1 1 2 2 2 3 4 5 6\n\nHmm, now 1 and 2 both occur three times each. What do we do? We say\nthere are two modes, and they are 1 and 2.\n\nWhy is the mode a measure of central tendency? Well, when we ask, \"what\nare my numbers like\", we can say, \"most of the number are, like a 1 (or\nwhatever the mode is)\".\n\nIs the mode a good measure of central tendency? That depends on your\nnumbers. For example, consider these numbers\n\n> 1 1 2 3 4 5 6 7 8 9\n\nHere, the mode is 1 again, because there are two 1s, and all of the\nother numbers occur once. But, are most of the numbers like, a 1. No,\nthey are mostly not 1s.\n\n\"Argh, so should I or should I not use the mode? I thought this class\nwas supposed to tell me what to do?\". There is no telling you what to\ndo. Every time you use a tool in statistics you have to think about what\nyou are doing and justify why what you are doing makes sense. Sorry.\n\n### Median\n\nThe **median** is the exact middle of the data. After all, we are asking\nabout central tendency, so why not go to the center of the data and see\nwhere we are. What do you mean middle of the data? Let's look at these\nnumbers:\n\n> 1 5 4 3 6 7 9\n\nUmm, OK. So, three is in the middle? Isn't that kind of arbitrary. Yes.\nBefore we can compute the median, we need to order the numbers from\nsmallest to largest.\n\n> 1 3 4 **5** 6 7 9\n\nNow, 5 is in the middle. And, by middle we mean in the middle. There are\nthree numbers to the left of 5, and three numbers to the right. So, five\nis definitely in the middle.\n\nOK fine, but what happens when there aren't an even number of numbers?\nThen the middle will be missing right? Let's see:\n\n> 1 2 3 4 5 6\n\nThere is no number between 3 and 4 in the data, the middle is empty. In\nthis case, we compute the median by figuring out the number in between 3\nand 4. So, the median would be 3.5.\n\nIs the median a good measure of central tendency? Sure, it is often very\nuseful. One property of the median is that it stays in the middle even\nwhen some of the other numbers get really weird. For example, consider\nthese numbers:\n\n> 1 2 3 4 4 4 **5** 6 6 6 7 7 1000\n\nMost of these numbers are smallish, but the 1000 is a big old weird\nnumber, very different from the rest. The median is still 5, because it\nis in the middle of these ordered numbers. We can also see that five is\npretty similar to most of the numbers (except for 1000). So, the median\ndoes a pretty good job of representing most of the numbers in the set,\nand it does so even if one or two of the numbers are very different from\nthe others.\n\nFinally, **outlier** is a term will we use to describe numbers that\nappear in data that are very different from the rest. 1000 is an\noutlier, because it lies way out there on the number line compared to\nthe other numbers. What to do with outliers is another topic we discuss\nsometimes throughout this course.\n\n### Mean\n\nHave you noticed this is a textbook about statistics that hasn't used a\nformula yet? That is about to change, but for those of you with formula\nanxiety, don't worry, we will do our best to explain them.\n\nThe **mean** is also called the average. And, we're guessing you might\nalready now what the average of a bunch of numbers is? It's the sum of\nthe numbers, divided by the number of number right? How do we express\nthat idea in a formula? Just like this:\n\n$Mean = \\bar{X} = \\frac{\\sum_{i=1}^{n} x_{i}}{N}$\n\n\"That looks like Greek to me\". Yup. The $\\sum$ symbol is called\n**sigma**, and it stands for the operation of summing. The little \"i\" on\nthe bottom, and the little \"n\" on the top refers to all of the numbers\nin the set, from the first number \"i\" to the last number \"n\". The\nletters are just arbitrary labels, called **variables** that we use for\ndescriptive purposes. The $x_{i}$ refers to individual numbers in the\nset. We sum up all of the numbers, then divide the sum by $N$, which is\nthe total number of numbers. Sometimes you will see $\\bar{X}$ to refer\nto the mean of all of the numbers.\n\nIn plain English, the formula looks like:\n\n$mean = \\frac{\\text{Sum of my numbers}}{\\text{Count of my numbers}}$\n\n\"Well, why didn't you just say that?\". We just did.\n\nLet's compute the mean for these five numbers:\n\n> 3 7 9 2 6\n\nAdd em up:\n\n> 3+7+9+2+6 = 27\n\nCount em up:\n\n> $i_{1}$ = 3, $i_{2}$ = 7, $i_{3}$ = 9, $i_{4}$ = 2, $i_{5}$ = 6; N=5,\n> because $i$ went from 1 to 5\n\nDivide em:\n\n> mean = 27 / 5 = 5.4\n\nOr, to put the numbers in the formula, it looks like this:\n\n$Mean = \\bar{X} = \\frac{\\sum_{i=1}^{n} x_{i}}{N} = \\frac{3+7+9+2+6}{5} = \\frac{27}{5} = 5.4$\n\nOK fine, that is how to compute the mean. But, like we imagined, you\nprobably already knew that, and if you didn't that's OK, now you do.\nWhat's next?\n\nIs the mean a good measure of central tendency? By now, you should know:\nit depends.\n\n### What does the mean mean?\n\nIt is not enough to know the formula for the mean, or to be able to use\nthe formula to compute a mean for a set of numbers. We believe in your\nability to add and divide numbers. What you really need to know is what\nthe mean really \"means\". This requires that you know what the mean does,\nand not just how to do it. Puzzled? Let's explain.\n\nCan you answer this question: What happens when you divide a sum of\nnumbers by the number of numbers? What are the consequences of doing\nthis? What is the formula doing? What kind of properties does the result\ngive us? FYI, the answer is not that we compute the mean.\n\nOK, so what happens when you divide any number by another number? Of\ncourse, the key word here is divide. We literally carve the number up\ntop in the numerator into pieces. How many times do we split the top\nnumber? That depends on the bottom number in the denominator. Watch:\n\n$\\frac{12}{3} = 4$\n\nSo, we know the answer is 4. But, what is really going on here is that\nwe are slicing and dicing up 12 aren't we. Yes, and we slicing 12 into\nthree parts. It turns out the size of those three parts is 4. So, now we\nare thinking of 12 as three different pieces $12 = 4 + 4 + 4$. I know\nthis will be obvious, but what kind of properties do our pieces have?\nYou mean the fours? Yup. Well, obviously they are all fours. Yes. The\npieces are all the same size. They are all equal. So, division equalizes\nthe numerator by the denominator...\n\n\"Umm, I think I learned this in elementary school, what does this have\nto do with the mean?\". The number on top of the formula for the mean is\njust another numerator being divided by a denominator isn't it. In this\ncase, the numerator is a sum of all the values in your data. What if it\nwas the sum of all of the 500 happiness ratings? The sum of all of them\nwould just be a single number adding up all the different ratings. If we\nsplit the sum up into equal parts representing one part for each\nperson's happiness what would we get? We would get 500 identical and\nequal numbers for each person. It would be like taking all of the\nhappiness in the world, then dividing it up equally, then to be fair,\ngiving back the same equal amount of happiness to everyone in the world.\nThis would make some people more happy than they were before, and some\npeople less happy right. Of course, that's because it would be\nequalizing the distribution of happiness for everybody. This process of\nequalization by dividing something into equal parts is what the **mean**\ndoes. See, it's more than just a formula. It's an idea. This is just the\nbeginning of thinking about these kinds of ideas. We will come back to\nthis idea about the mean, and other ideas, in later chapters.\n\n> Pro tip: The mean is the one and only number that can take the place\n> of every number in the data, such that when you add up all the equal\n> parts, you get back the original sum of the data.\n\n### All together now\n\nJust to remind ourselves of the mode, median, and mean, take a look at\nthe next histogram in \\@fig-meanmodemed. We have overlaid the location\nof the mean (red), median (green), and mode (blue). For this dataset,\nthe three measures of central tendency all give different answers. The\nmean is the largest because it is influenced by large numbers, even if\nthey occur rarely. The mode and median are insensitive to large numbers\nthat occur infrequently, so they have smaller values.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A histogram with the mean (red), the median (green), and the mode (blue)](chapter_files/figure-html/fig-meanmodemed-1.png){#fig-meanmodemed width=75%}\n:::\n:::\n\n\n\n\n## Measures of Variation (Different*ness*)\n\nWhat did you do when you wrote essays in high school about a book you\nread? Probably compare and contrast something right? When you summarize\ndata, you do the same thing. Measures of central tendency give us\nsomething like comparing does, they tell us stuff about what is the\nsame. Measures of variation give us something like contrasting does,\nthey tell us stuff about what is different.\n\nFirst, we note that whenever you see a bunch of numbers that aren't the\nsame, you already know there are some differences. This means the\nnumbers vary, and there is variation in the size of the numbers.\n\n### The Range\n\nConsider these 10 numbers, that I already ordered from smallest to\nlargest for you:\n\n> 1 3 4 5 5 6 7 8 9 24\n\nThe numbers have variation, because they are not all the same. We can\nuse the range to describe the width of the variation. The range refers\nto the **minimum** (smallest value) and **maximum** (largest value) in\nthe set. So, the range would be 1 and 24.\n\nThe range is a good way to quickly summarize the boundaries of your data\nin just two numbers. By computing the range we know that none of the\ndata is larger or smaller than the range. And, it can alert you to\noutliers. For example, if you are expecting your numbers to be between 1\nand 7, but you find the range is 1 - 340,500, then you know you have\nsome big numbers that shouldn't be there, and then you can try to figure\nout why those numbers occurred (and potentially remove them if something\nwent wrong).\n\n### The Difference Scores\n\nIt would be nice to summarize the amount of different*ness* in the data.\nHere's why. If you thought that raw data (lots of numbers) is too big to\nlook at, then you will be frightened to contemplate how many differences\nthere are to look at. For example, these 10 numbers are easy to look at:\n\n> 1 3 4 5 5 6 7 8 9 24\n\nBut, what about the difference between the numbers, what do those look\nlike? We can compute the difference scores between each number, then put\nthem in a matrix like the one below:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|   |   1|   3|   4|   5|   5|   6|   7|   8|   9| 24|\n|:--|---:|---:|---:|---:|---:|---:|---:|---:|---:|--:|\n|1  |   0|   2|   3|   4|   4|   5|   6|   7|   8| 23|\n|3  |  -2|   0|   1|   2|   2|   3|   4|   5|   6| 21|\n|4  |  -3|  -1|   0|   1|   1|   2|   3|   4|   5| 20|\n|5  |  -4|  -2|  -1|   0|   0|   1|   2|   3|   4| 19|\n|5  |  -4|  -2|  -1|   0|   0|   1|   2|   3|   4| 19|\n|6  |  -5|  -3|  -2|  -1|  -1|   0|   1|   2|   3| 18|\n|7  |  -6|  -4|  -3|  -2|  -2|  -1|   0|   1|   2| 17|\n|8  |  -7|  -5|  -4|  -3|  -3|  -2|  -1|   0|   1| 16|\n|9  |  -8|  -6|  -5|  -4|  -4|  -3|  -2|  -1|   0| 15|\n|24 | -23| -21| -20| -19| -19| -18| -17| -16| -15|  0|\n\n\n:::\n:::\n\n\n\n\nWe are looking at all of the possible differences between each number\nand every other number. So, in the top left, the difference between 1\nand itself is 0. One column over to the right, the difference between 3\nand 1 (3-1) is 2, etc. As you can see, this is a 10x10 matrix, which\nmeans there are 100 differences to look at. Not too bad, but if we had\n500 numbers, then we would have 500\\*500 = 250,000 differences to look\nat (go for it if you like looking at that sort of thing).\n\nPause for a simple question. What would this matrix look like if all of\nthe 10 numbers in our data were the same number? It should look like a\nbunch of 0s right? Good. In that case, we could easily see that the\nnumbers have no variation.\n\nBut, when the numbers are different, we can see that there is a very\nlarge matrix of difference scores. How can we summarize that? How about\nwe apply what we learned from the previous section on measures of\ncentral tendency. We have a lot of differences, so we could ask\nsomething like, what is the average difference that we have? So, we\ncould just take all of our differences, and compute the mean difference\nright? What do you think would happen if we did that?\n\nLet's try it out on these three numbers:\n\n> 1 2 3\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|   |  1|  2|  3|\n|:--|--:|--:|--:|\n|1  |  0|  1|  2|\n|2  | -1|  0|  1|\n|3  | -2| -1|  0|\n\n\n:::\n:::\n\n\n\n\nYou might already guess what is going to happen. Let's compute the mean:\n\n$\\text{mean of difference scores} = \\frac{0+1+2-1+0+1-2-1+0}{9} = \\frac{0}{9} = 0$\n\nUh oh, we get zero for the mean of the difference scores. This will\nalways happen whenever you take the mean of the difference scores. We\ncan see that there are some differences between the numbers, so using 0\nas the summary value for the variation in the numbers doesn't make much\nsense.\n\nFurthermore, you might also notice that the matrices of difference\nscores are redundant. The diagonal is always zero, and numbers on one\nside of the diagonal are the same as the numbers on the other side,\nexcept their signs are reversed. So, that's one reason why the\ndifference scores add up to zero.\n\nThese are little problems that can be solved by computing the\n**variance** and the **standard deviation**. For now, the standard\ndeviation is a just a trick that we use to avoid getting a zero. But,\nlater we will see it has properties that are important for other\nreasons.\n\n### The Variance\n\nVariability, variation, variance, vary, variable, varying, variety.\nConfused yet? Before we describe **the variance**, we want to you be OK\nwith how this word is used. First, don't forget the big picture. We know\nthat variability and variation refers to the big idea of differences\nbetween numbers. We can even use the word variance in the same way. When\nnumbers are different, they have variance.\n\n::: callout-note\nThe formulas for variance and standard deviation depend on whether you\nthink your data represents an entire population of numbers, or is sample\nfrom the population. We discuss this issue in later on. For now, we\ndivide by N, later we discuss why you will often divide by N-1 instead.\n:::\n\nThe word **variance** also refers to a specific summary statistic, the\nsum of the squared deviations from the mean. Hold on what? Plain English\nplease. The variance is the sum of the squared difference scores, where\nthe difference scores are computed between each score and the mean. What\nare these scores? The scores are the numbers in the data set. Let's see\nthe formula in English first:\n\n$variance = \\frac{\\text{Sum of squared difference scores}}{\\text{Number of Scores}}$\n\n#### Deviations from the mean, Difference scores from the mean\n\nWe got a little bit complicated before when we computed the difference\nscores between all of the numbers in the data. Let's do it again, but in\na more manageable way. This time, we calculate the difference between\neach score and the mean. The idea here is\n\n1.  We can figure out how similar our scores are by computing the mean\n2.  Then we can figure out how different our scores are from the mean\n\nThis could tell us, 1) something about whether our scores are really all\nvery close to the mean (which could help us know if the mean is good\nrepresentative number of the data), and 2) something about how much\ndifferences there are in the numbers.\n\nTake a look at this table:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|scores |values |mean |Difference_from_Mean |\n|:------|:------|:----|:--------------------|\n|1      |1      |4.5  |-3.5                 |\n|2      |6      |4.5  |1.5                  |\n|3      |4      |4.5  |-0.5                 |\n|4      |2      |4.5  |-2.5                 |\n|5      |6      |4.5  |1.5                  |\n|6      |8      |4.5  |3.5                  |\n|Sums   |27     |27   |0                    |\n|Means  |4.5    |4.5  |0                    |\n\n\n:::\n:::\n\n\n\n\nThe first column shows we have 6 scores in the data set, and the `value`\ncolumns shows each score. The sum of the values, and the mean is\npresented on the last two rows. The sum and the mean were obtained by:\n\n$\\frac{1+6+4+2+6+8}{6} = \\frac{27}{6} = 4.5$.\n\nThe third column `mean`, appears a bit silly. We are just listing the\nmean once for every score. If you think back to our discussion about the\nmeaning of the mean, then you will remember that it equally distributes\nthe total sum across each data point. We can see that here, if we treat\neach score as the mean, then every score is a 4.5. We can also see that\nadding up all of the means for each score gives us back 27, which is the\nsum of the original values. Also, we see that if we find the mean of the\nmean scores, we get back the mean (4.5 again).\n\nAll of the action is occurring in the fourth column,\n`Difference_from_Mean`. Here, we are showing the difference scores from\nthe mean, using $X_{i}-\\bar{X}$. In other words, we subtracted the mean\nfrom each score. So, the first score, 1, is -3.5 from the mean, the\nsecond score, 6, is +1.5 from the mean, and so on.\n\nNow, we can look at our original scores and we can look at their\ndifferences from the mean. Notice, we don't have a matrix of raw\ndifference scores, so it is much easier to look at out. But, we still\nhave a problem:\n\nWe can see that there are non-zero values in the difference scores, so\nwe know there are a differences in the data. But, when we add them all\nup, we still get zero, which makes it seem like there are a total of\nzero differences in the data...Why does this happen...and what to do\nabout it?\n\n#### The mean is the balancing point in the data\n\nOne brief pause here to point out another wonderful property of the\nmean. It is the balancing point in the data. If you take a pen or pencil\nand try to balance it on your figure so it lays flat what are you doing?\nYou need to find the center of mass in the pen, so that half of it is on\none side, and the other half is on the other side. That's how balancing\nworks. One side = the other side.\n\nWe can think of data as having mass or weight to it. If we put our data\non our bathroom scale, we could figure out how heavy it was by summing\nit up. If we wanted to split the data down the middle so that half of\nthe weight was equal to the other half, then we could balance the data\non top of a pin. The mean of the data tells you where to put the pin. It\nis the location in the data, where the numbers on the one side add up to\nthe same sum as the numbers on the other side.\n\nIf we think this through, it means that the sum of the difference scores\nfrom the mean will always add up to zero. This is because the numbers on\none side of the mean will always add up to -x (whatever the sum of those\nnumbers is), and the numbers of the other side of the mean will always\nadd up to +x (which will be the same value only positive). And:\n\n$-x + x = 0$, right.\n\nRight.\n\n#### The squared deviations\n\nSome devious someone divined a solution to the fact that differences\nscores from the mean always add to zero. Can you think of any solutions?\nFor example, what could you do to the difference scores so that you\ncould add them up, and they would weigh something useful, that is they\nwould not be zero?\n\nThe devious solution is to square the numbers. Squaring numbers converts\nall the negative numbers to positive numbers. For example, $2^2 = 4$,\nand $-2^2 = 4$. Remember how squaring works, we multiply the number\ntwice: $2^2 = 2*2 = 4$, and $-2^2 = -2*-2 = 4$. We use the term\n**squared deviations** to refer to differences scores that have been\nsquared. Deviations are things that move away from something. The\ndifference scores move away from the mean, so we also call them\n**deviations**.\n\nLet's look at our table again, but add the squared deviations.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|scores |values |mean |Difference_from_Mean |Squared_Deviations |\n|:------|:------|:----|:--------------------|:------------------|\n|1      |1      |4.5  |-3.5                 |12.25              |\n|2      |6      |4.5  |1.5                  |2.25               |\n|3      |4      |4.5  |-0.5                 |0.25               |\n|4      |2      |4.5  |-2.5                 |6.25               |\n|5      |6      |4.5  |1.5                  |2.25               |\n|6      |8      |4.5  |3.5                  |12.25              |\n|Sums   |27     |27   |0                    |35.5               |\n|Means  |4.5    |4.5  |0                    |5.91666666666667   |\n\n\n:::\n:::\n\n\n\n\nOK, now we have a new column called `squared_deviations`. These are just\nthe difference scores squared. So, $-3.5^2 = 12.25$, etc. You can\nconfirm for yourself with your cellphone calculator.\n\nNow that all of the squared deviations are positive, we can add them up.\nWhen we do this we create something very special called the sum of\nsquares (SS), also known as the sum of the squared deviations from the\nmean. We will talk at length about this SS later on in the ANOVA\nchapter. So, when you get there, remember that you already know what it\nis, just some sums of some squared deviations, nothing fancy.\n\n#### Finally, the variance\n\nGuess what, we already computed the variance. It already happened, and\nmaybe you didn't notice. \"Wait, I missed that, what happened?\".\n\nFirst, see if you can remember what we are trying to do here. Take a\npause, and see if you can tell yourself what problem we are trying\nsolve.\n\n> pause\n\nWithout further ado, we are trying to get a summary of the differences\nin our data. There are just as many difference scores from the mean as\nthere are data points, which can be a lot, so it would be nice to have a\nsingle number to look at, something like a mean, that would tell us\nabout the average differences in the data.\n\nIf you look at the table, you can see we already computed the mean of\nthe squared deviations. First, we found the sum (SS), then below that we\ncalculated the mean = 5.916 repeating. This is **the variance**. The\nvariance is the mean of the sum of the squared deviations:\n\n$variance = \\frac{SS}{N}$, where SS is the sum of the squared\ndeviations, and N is the number of observations.\n\nOK, now what. What do I do with the variance? What does this number\nmean? Good question. The variance is often an unhelpful number to look\nat. Why? Because it is not in the same scale as the original data. This\nis because we squared the difference scores before taking the mean.\nSquaring produces large numbers. For example, we see a 12.25 in there.\nThat's a big difference, bigger than any difference between any two\noriginal values. What to do? How can we bring the numbers back down to\ntheir original unsquared size?\n\nIf you are thinking about taking the square root, that's a ding ding\nding, correct answer for you. We can always unsquare anything by taking\nthe square root. So, let's do that to 5.916. $\\sqrt{5.916} =$\n2.4322829.\n\n### The Standard Deviation\n\nOops, we did it again. We already computed the standard deviation, and\nwe didn't tell you. The standard deviation is the square root of the\nvariance...At least, it is right now, until we complicate matters for\nyou in the next chapter.\n\nHere is the formula for the standard deviation:\n\n$\\text{standard deviation} = \\sqrt{Variance} = \\sqrt{\\frac{SS}{N}}$.\n\nWe could also expand this to say:\n\n$\\text{standard deviation} = \\sqrt{\\frac{\\sum_{i}^{n}({x_{i}-\\bar{x})^2}}{N}}$\n\nDon't let those big square root signs put you off. Now, you know what\nthey are doing there. Just bringing our measure of the variance back\ndown to the original size of the data. Let's look at our table again:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|scores |values |mean |Difference_from_Mean |Squared_Deviations |\n|:------|:------|:----|:--------------------|:------------------|\n|1      |1      |4.5  |-3.5                 |12.25              |\n|2      |6      |4.5  |1.5                  |2.25               |\n|3      |4      |4.5  |-0.5                 |0.25               |\n|4      |2      |4.5  |-2.5                 |6.25               |\n|5      |6      |4.5  |1.5                  |2.25               |\n|6      |8      |4.5  |3.5                  |12.25              |\n|Sums   |27     |27   |0                    |35.5               |\n|Means  |4.5    |4.5  |0                    |5.91666666666667   |\n\n\n:::\n:::\n\n\n\n\nWe measured the standard deviation as 2.4322829. Notice this\nnumber fits right in the with differences scores from the mean. All of\nthe scores are kind of in and around + or - 2.4322829. Whereas, if\nwe looked at the variance, 5.916 is just too big, it doesn't summarize\nthe actual differences very well.\n\nWhat does all this mean? Well, if someone told they had some number with\na mean of 4.5 (like the values in our table), and a standard deviation\nof 2.4322829, you would get a pretty good summary of the numbers.\nYou would know that many of the numbers are around 4.5, and you would\nknow that not all of the numbers are 4.5. You would know that the\nnumbers spread around 4.5. You also know that the spread isn't super\nhuge, it's only + or - 2.4322829 on average. That's a good\nstarting point for describing numbers.\n\nIf you had loads of numbers, you could reduce them down to the mean and\nthe standard deviation, and still be pretty well off in terms of getting\na sense of those numbers.\n\n## Using Descriptive Statistics with data\n\nRemember, you will be learning how to compute descriptive statistics\nusing software in the labs. Check out the [DataSkills for\ndescriptives](https://www.youtube.com/watch?v=dQw4w9WgXcQ) to see some\nexamples of working with real data.\n\n## Rolling your own descriptive statistics\n\nWe spent many paragraphs talking about variation in numbers, and how to\nuse calculate the **variance** and **standard deviation** to summarize\nthe average differences between numbers in a data set. The basic process\nwas to 1) calculate some measure of the differences, then 2) average the\ndifferences to create a summary. We found that we couldn't average the\nraw difference scores, because we would always get a zero. So, we\nsquared the differences from the mean, then averaged the squared\ndifferences differences. Finally, we square rooted our measure to bring\nthe summary back down to the scale of the original numbers.\n\nPerhaps you haven't heard, but there is more than one way to skin a cat,\nbut we prefer to think of this in terms of petting cats, because some of\nus love cats. Jokes aside, perhaps you were also thinking that the\nproblem of summing differences scores (so that they don't equal zero),\ncan be solved in more than one way. Can you think of a different way,\nbesides squaring?\n\n### Absolute deviations\n\nHow about just taking the absolute value of the difference scores.\nRemember, the absolute value converts any number to a positive value.\nCheck out the following table:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|scores |values |mean |Difference_from_Mean |Absolute_Deviations |\n|:------|:------|:----|:--------------------|:-------------------|\n|1      |1      |4.5  |-3.5                 |3.5                 |\n|2      |6      |4.5  |1.5                  |1.5                 |\n|3      |4      |4.5  |-0.5                 |0.5                 |\n|4      |2      |4.5  |-2.5                 |2.5                 |\n|5      |6      |4.5  |1.5                  |1.5                 |\n|6      |8      |4.5  |3.5                  |3.5                 |\n|Sums   |27     |27   |0                    |13                  |\n|Means  |4.5    |4.5  |0                    |2.16666666666667    |\n\n\n:::\n:::\n\n\n\n\nThis works pretty well too. By converting the difference scores from the\nmean to positive values, we can now add them up and get a non-zero value\n(if there are differences). Then, we can find the mean of the sum of the\nabsolute deviations. If we were to map the terms sum of squares (SS),\nvariance and standard deviation onto these new measures based off of the\nabsolute deviation, how would the mapping go? For example, what value in\nthe table corresponds to the SS? That would be the sum of absolute\ndeviations in the last column. How about the variance and standard\ndeviation, what do those correspond to? Remember that the variance is\nmean ($SS/N$), and the standard deviation is a square-rooted mean\n($\\sqrt{SS/N}$). In the table above we only have one corresponding mean,\nthe mean of the sum of the absolute deviations. So, we have a\n**variance** measure that does not need to be square rooted. We might\nsay the mean absolute deviation, is doing double-duty as a variance and\na standard-deviation. Neat.\n\n### Other sign-inverting operations\n\nIn principle, we could create lots of different summary statistics for\nvariance that solve the summing to zero problem. For example, we could\nraise every difference score to any even numbered power beyond 2 (which\nis the square). We could use, 4, 6, 8, 10, etc. There is an infinity of\neven numbers, so there is an infinity of possible variance statistics.\nWe could also use odd numbers as powers, and then take their absolute\nvalue. Many things are possible. The important aspect to any of this is\nto have a reason for what you are doing, and to choose a method that\nworks for the data-analysis problem you are trying to solve. Note also,\nwe bring up this general issue because we want you to understand that\nstatistics is a creative exercise. We invent things when we need them,\nand we use things that have already been invented when they work for the\nproblem at hand.\n\n## Remember to look at your data\n\nDescriptive statistics are great and we will use them a lot in the\ncourse to describe data. You may suspect that descriptive statistics\nalso have some short-comings. This is very true. They are compressed\nsummaries of large piles of numbers. They will almost always be unable\nto represent all of the numbers fairly. There are also different kinds\nof descriptive statistics that you could use, and it sometimes not clear\nwhich one's you should use.\n\nPerhaps the most important thing you can do when using descriptives is\nto use them in combination with looking at the data in a graph form.\nThis can help you see whether or not your descriptives are doing a good\njob of representing the data.\n\n### Anscombe's Quartet\n\nTo hit this point home, and to get you thinking about the issues we\ndiscuss in the next chapter, check this out. It's called Anscombe's\nQuartet, because these interesting graphs and numbers and numbers were\nproduced by @Anscombe1973. In @fig-anscombe you are looking at pairs of\nmeasurements. Each graph has an X and Y axis, and each point represents\ntwo measurements. Each of the graphs looks very different, right?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Anscombe's Quartet](chapter_files/figure-html/fig-anscombe-1.png){#fig-anscombe width=75%}\n:::\n:::\n\n\n\n\nWell, would you be surprised if I told that the descriptive statistics\nfor the numbers in these graphs are exactly the same? It turns out they\ndo have the same descriptive statistics. In the table below I present\nthe mean and variance for the x-values in each graph, and the mean and\nthe variance for the y-values in each graph.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|quartet | mean_x| var_x|   mean_y|    var_y|\n|:-------|------:|-----:|--------:|--------:|\n|1       |      9|    11| 7.500909| 4.127269|\n|2       |      9|    11| 7.500909| 4.127629|\n|3       |      9|    11| 7.500000| 4.122620|\n|4       |      9|    11| 7.500909| 4.123249|\n\n\n:::\n:::\n\n\n\n\nThe descriptives are all the same! Anscombe put these special numbers\ntogether to illustrate the point of graphing your numbers. If you only\nlook at your descriptives, you don't know what patterns in the data they\nare hiding. If you look at the graph, then you can get a better\nunderstanding.\n\n### Datasaurus Dozen\n\nIf you thought that Anscombe's quartet was neat, you should take a look\nat the [Datasaurus\nDozen](https://www.autodeskresearch.com/publications/samestats)\n[@matejka2017same]. Scroll down to see the examples. You will be looking\nat dot plots. The dot plots show many different patterns, including\ndinosaurs! What's amazing is that all of the dots have very nearly the\nsame descriptive statistics. Just another reminder to look at your data,\nit might look like a dinosaur!\n\n## Videos\n\n### Measures of center: Mode\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hQ2p-QQpGso\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n\n</iframe>\n\n### Measures of center: Median and Mean\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BopmCXCjq08\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n\n</iframe>\n\n### Standard deviation part I\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8Yguf93s5dI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n\n</iframe>\n\n### Standard deviation part II\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KodmsOXScBc\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n\n</iframe>\n\n<!--------------- appendices go here ----------------->\n\n##### Session info {.appendix}\n",
    "supporting": [
      "chapter_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}